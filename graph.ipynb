{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a08677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pyvis.network import Network\n",
    "import os\n",
    "\n",
    "# --- ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ ---\n",
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "data = np.load(\"faiss_metadata.npz\", allow_pickle=True)\n",
    "metadata_list = data[\"metadata_list\"].tolist()\n",
    "paragraph_embeddings = data[\"embeddings\"]\n",
    "\n",
    "# --- æ–‡æ›¸å˜ä½ã®å¹³å‡ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¨ˆç®— ---\n",
    "def compute_doc_embeddings(paragraph_embeddings, metadata_list):\n",
    "    doc_vectors = defaultdict(list)\n",
    "    for emb, meta in zip(paragraph_embeddings, metadata_list):\n",
    "        doc_vectors[meta[\"source\"]].append(emb)\n",
    "    \n",
    "    doc_embeddings = {}\n",
    "    for source, vectors in doc_vectors.items():\n",
    "        vecs = np.vstack(vectors)\n",
    "        vecs /= np.linalg.norm(vecs, axis=1, keepdims=True)\n",
    "        mean_vec = np.mean(vecs, axis=0)\n",
    "        mean_vec /= np.linalg.norm(mean_vec)\n",
    "        doc_embeddings[source] = mean_vec.astype(\"float32\")\n",
    "    return doc_embeddings\n",
    "\n",
    "# --- ã‚¯ã‚¨ãƒªã«å¯¾ã™ã‚‹ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’æ§‹ç¯‰ã—ã¦å¯è¦–åŒ– ---\n",
    "def build_query_network(query, similarity_threshold=0.6, max_nodes=30, edge_threshold=0.7):\n",
    "    print(f\"\\nğŸ” ã‚¯ã‚¨ãƒª: '{query}'\")\n",
    "    print(f\"ğŸ“ é¡ä¼¼åº¦ã—ãã„å€¤: {similarity_threshold}, è¡¨ç¤ºãƒãƒ¼ãƒ‰ä¸Šé™: {max_nodes}, ã‚¨ãƒƒã‚¸é–¾å€¤: {edge_threshold}\")\n",
    "    \n",
    "    # æ–‡æ›¸ãƒ™ã‚¯ãƒˆãƒ«è¨ˆç®— & ã‚¯ã‚¨ãƒªãƒ™ã‚¯ãƒˆãƒ«åŒ–\n",
    "    doc_embeddings = compute_doc_embeddings(paragraph_embeddings, metadata_list)\n",
    "    query_vec = model.encode([query], normalize_embeddings=True)[0]\n",
    "\n",
    "    # é¡ä¼¼åº¦ã‚’è¨ˆç®—\n",
    "    similarities = {\n",
    "        doc: float(np.dot(query_vec, emb))\n",
    "        for doc, emb in doc_embeddings.items()\n",
    "    }\n",
    "\n",
    "    # é¡ä¼¼åº¦ã—ãã„å€¤ã§ãƒ•ã‚£ãƒ«ã‚¿ â†’ ã‚¹ã‚³ã‚¢é †ã«ä¸Šä½max_nodesã¾ã§å–å¾—\n",
    "    sorted_docs = sorted(\n",
    "        [(doc, sim) for doc, sim in similarities.items() if sim >= similarity_threshold],\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )[:max_nodes]\n",
    "\n",
    "    if not sorted_docs:\n",
    "        print(\"âš ï¸ è©²å½“ã™ã‚‹æ–‡æ›¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æ¡ä»¶ã‚’ã‚†ã‚‹ã‚ã¦å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")\n",
    "        return\n",
    "\n",
    "    selected_docs = dict(sorted_docs)\n",
    "    print(f\"âœ… è¡¨ç¤ºå¯¾è±¡ãƒãƒ¼ãƒ‰æ•°: {len(selected_docs)}\")\n",
    "\n",
    "    # --- ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç”Ÿæˆ ---\n",
    "    net = Network(height=\"600px\", width=\"100%\", notebook=True)\n",
    "    net.force_atlas_2based()\n",
    "\n",
    "    # ãƒãƒ¼ãƒ‰è¿½åŠ \n",
    "    for doc, sim in selected_docs.items():\n",
    "        title = next((m[\"title\"] for m in metadata_list if m[\"source\"] == doc), doc)\n",
    "        net.add_node(doc, label=title[:50], title=title, value=sim)\n",
    "\n",
    "    # ã‚¨ãƒƒã‚¸è¿½åŠ ï¼ˆæ–‡æ›¸é–“é¡ä¼¼åº¦ï¼‰\n",
    "    docs = list(selected_docs.keys())\n",
    "    for i in range(len(docs)):\n",
    "        for j in range(i + 1, len(docs)):\n",
    "            sim_ij = float(np.dot(doc_embeddings[docs[i]], doc_embeddings[docs[j]]))\n",
    "            if sim_ij > edge_threshold:\n",
    "                net.add_edge(docs[i], docs[j], value=sim_ij)\n",
    "\n",
    "    # --- HTMLè¡¨ç¤º ---\n",
    "    output_path = \"query_network.html\"\n",
    "    net.show(output_path)\n",
    "    print(f\"ğŸŒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ '{output_path}' ã«ä¿å­˜ã—ã¾ã—ãŸã€‚ãƒ–ãƒ©ã‚¦ã‚¶ã§é–‹ã„ã¦ç¢ºèªã—ã¦ãã ã•ã„ã€‚\")\n",
    "\n",
    "# === å®Ÿè¡Œä¾‹ ===\n",
    "build_query_network(\n",
    "    query=\"filamin-A\",  # ä»»æ„ã®ã‚¯ã‚¨ãƒªã«å¤‰æ›´å¯èƒ½\n",
    "    similarity_threshold=0.4,  # ã‚¯ã‚¨ãƒªã¨ã®é¡ä¼¼åº¦ãŒã“ã‚Œä»¥ä¸Šã®è«–æ–‡ã®ã¿å¯¾è±¡\n",
    "    max_nodes=40,              # ä¸Šä½40ä»¶ã¾ã§ã‚’è¡¨ç¤ºï¼ˆå¤šã™ãã‚‹ã¨é‡ããªã‚‹ï¼‰\n",
    "    edge_threshold=0.7         # ã‚¨ãƒƒã‚¸ï¼ˆè«–æ–‡åŒå£«ã®ã¤ãªãŒã‚Šï¼‰ã‚’å¼µã‚‹ãŸã‚ã®ã—ãã„å€¤\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539ef91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pyvis.network import Network\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from collections import defaultdict\n",
    "\n",
    "# --- ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ ---\n",
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "data = np.load(\"faiss_metadata.npz\", allow_pickle=True)\n",
    "metadata_list = data[\"metadata_list\"].tolist()\n",
    "paragraph_embeddings = data[\"embeddings\"]\n",
    "\n",
    "# --- æ–‡æ›¸å˜ä½ã®å¹³å‡ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¨ˆç®— ---\n",
    "def compute_doc_embeddings(paragraph_embeddings, metadata_list):\n",
    "    doc_vectors = defaultdict(list)\n",
    "    for emb, meta in zip(paragraph_embeddings, metadata_list):\n",
    "        doc_vectors[meta[\"source\"]].append(emb)\n",
    "\n",
    "    doc_embeddings = {}\n",
    "    doc_titles = {}\n",
    "    for source, vectors in doc_vectors.items():\n",
    "        vecs = np.vstack(vectors)\n",
    "        vecs /= np.linalg.norm(vecs, axis=1, keepdims=True)\n",
    "        mean_vec = np.mean(vecs, axis=0)\n",
    "        mean_vec /= np.linalg.norm(mean_vec)\n",
    "        doc_embeddings[source] = mean_vec.astype(\"float32\")\n",
    "        title = next((m[\"title\"] for m in metadata_list if m[\"source\"] == source), source)\n",
    "        doc_titles[source] = title\n",
    "    return doc_embeddings, doc_titles\n",
    "\n",
    "# --- æº–å‚™ ---\n",
    "doc_embeddings, doc_titles = compute_doc_embeddings(paragraph_embeddings, metadata_list)\n",
    "title_to_source = {title: source for source, title in doc_titles.items()}\n",
    "all_titles = sorted(title_to_source.keys())\n",
    "\n",
    "# --- ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æç”» ---\n",
    "def build_paper_network(center_source, top_k=20, edge_threshold=0.75):\n",
    "    center_vec = doc_embeddings[center_source]\n",
    "    similarities = {\n",
    "        doc: float(np.dot(center_vec, vec))\n",
    "        for doc, vec in doc_embeddings.items()\n",
    "        if doc != center_source\n",
    "    }\n",
    "\n",
    "    top_docs = sorted(similarities.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "\n",
    "    net = Network(height=\"600px\", width=\"100%\", notebook=True)\n",
    "    #net.force_atlas_2based()ã€€ã°ã­ã®ã‚ˆã†ã«ã—ãŸã„å ´åˆ\n",
    "    net.set_options('''\n",
    "    {\n",
    "    \"physics\": {\n",
    "        \"enabled\": false\n",
    "    }\n",
    "    }\n",
    "    ''')\n",
    "\n",
    "    center_title = doc_titles.get(center_source, center_source)\n",
    "    net.add_node(center_source, label=center_title[:50], title=center_title, value=1.0, color=\"red\")\n",
    "\n",
    "    for doc, score in top_docs:\n",
    "        title = doc_titles.get(doc, doc)\n",
    "        net.add_node(doc, label=title[:50], title=title, value=score)\n",
    "        if score > edge_threshold:\n",
    "            net.add_edge(center_source, doc, value=score)\n",
    "\n",
    "    for i in range(len(top_docs)):\n",
    "        for j in range(i + 1, len(top_docs)):\n",
    "            doc1, doc2 = top_docs[i][0], top_docs[j][0]\n",
    "            sim_ij = float(np.dot(doc_embeddings[doc1], doc_embeddings[doc2]))\n",
    "            if sim_ij > edge_threshold:\n",
    "                net.add_edge(doc1, doc2, value=sim_ij)\n",
    "\n",
    "    net.show(\"center_paper_network.html\")\n",
    "    print(\"âœ… ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ 'center_paper_network.html' ã«ä¿å­˜ã—ã¾ã—ãŸã€‚\")\n",
    "\n",
    "# --- UIéƒ¨å“ ---\n",
    "search_box = widgets.Text(description=\"ã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢:\", layout=widgets.Layout(width='500px'))\n",
    "title_dropdown = widgets.Dropdown(options=[], description=\"å€™è£œ:\", layout=widgets.Layout(width='95%'))\n",
    "run_button = widgets.Button(description=\"ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¡¨ç¤º\")\n",
    "\n",
    "# --- ã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢å‡¦ç† ---\n",
    "def on_search_change(change):\n",
    "    query = search_box.value.strip().lower()\n",
    "    if not query:\n",
    "        title_dropdown.options = []\n",
    "        return\n",
    "    filtered = [t for t in all_titles if query in t.lower()]\n",
    "    title_dropdown.options = filtered if filtered else [\"è©²å½“ãªã—\"]\n",
    "\n",
    "search_box.observe(on_search_change, names='value')\n",
    "\n",
    "# --- å®Ÿè¡Œå‡¦ç† ---\n",
    "def on_run_clicked(b):\n",
    "    selected_title = title_dropdown.value\n",
    "    if selected_title == \"è©²å½“ãªã—\":\n",
    "        print(\"âš ï¸ å€™è£œãŒã‚ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "        return\n",
    "    selected_source = title_to_source[selected_title]\n",
    "    build_paper_network(center_source=selected_source)\n",
    "\n",
    "run_button.on_click(on_run_clicked)\n",
    "\n",
    "# --- è¡¨ç¤º ---\n",
    "display(search_box, title_dropdown, run_button)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f987e387",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jupyter Notebookå†…ã§ã‚°ãƒ©ãƒ•è¡¨ç¤ºï¼ˆipycytoscapeï¼‰+ã‚¯ãƒªãƒƒã‚¯ã§Zoteroãƒªãƒ³ã‚¯ã‚’é–‹ãæ©Ÿèƒ½å¯¾å¿œ\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from ipycytoscape import CytoscapeWidget, Node, Edge\n",
    "from IPython.display import display\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import webbrowser\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# === ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®šï¼ˆã“ã“ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ï¼‰ ===\n",
    "TOP_K = 20                      # è¡¨ç¤ºã™ã‚‹ãƒãƒ¼ãƒ‰æ•°ï¼ˆä¸­å¿ƒè«–æ–‡ã«ä¼¼ã¦ã„ã‚‹ã‚‚ã®ï¼‰\n",
    "EDGE_THRESHOLD = 0.75          # ã‚¨ãƒƒã‚¸ã‚’ã¤ãªãé¡ä¼¼åº¦ã®é–¾å€¤\n",
    "\n",
    "# COSEãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆåˆæœŸè¨­å®šï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ï¼‰\n",
    "COSE_LAYOUT_PARAMS = {\n",
    "    \"name\": \"cose\",\n",
    "    \"animate\": False\n",
    "}\n",
    "\n",
    "# --- ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿ ---\n",
    "load_dotenv()\n",
    "ZOTERO_USER_ID = os.getenv(\"ZOTERO_USER_ID\")\n",
    "ZOTERO_API_KEY = os.getenv(\"ZOTERO_API_KEY\")\n",
    "PDF_FOLDER = os.getenv(\"PDF_FOLDER\", \"\")\n",
    "\n",
    "# --- ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ ---\n",
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "data = np.load(\"faiss_metadata.npz\", allow_pickle=True)\n",
    "metadata_list = data[\"metadata_list\"].tolist()\n",
    "paragraph_embeddings = data[\"embeddings\"]\n",
    "\n",
    "# --- æ–‡æ›¸å¹³å‡ãƒ™ã‚¯ãƒˆãƒ«ã®è¨ˆç®— ---\n",
    "def compute_doc_embeddings(paragraph_embeddings, metadata_list):\n",
    "    doc_vectors = defaultdict(list)\n",
    "    for emb, meta in zip(paragraph_embeddings, metadata_list):\n",
    "        doc_vectors[meta[\"source\"]].append(emb)\n",
    "\n",
    "    doc_embeddings = {}\n",
    "    doc_titles = {}\n",
    "    for source, vectors in doc_vectors.items():\n",
    "        vecs = np.vstack(vectors)\n",
    "        vecs /= np.linalg.norm(vecs, axis=1, keepdims=True)\n",
    "        mean_vec = np.mean(vecs, axis=0)\n",
    "        mean_vec /= np.linalg.norm(mean_vec)\n",
    "        doc_embeddings[source] = mean_vec.astype(\"float32\")\n",
    "        title = next((m[\"title\"] for m in metadata_list if m[\"source\"] == source), source)\n",
    "        doc_titles[source] = title\n",
    "    return doc_embeddings, doc_titles\n",
    "\n",
    "# --- Zoteroãƒªãƒ³ã‚¯ã¨parentKeyå–å¾— ---\n",
    "def get_zotero_link_and_key(source):\n",
    "    pdf_name = source.replace(PDF_FOLDER, \"\").lstrip(\"/\\\\\")\n",
    "    url = f\"https://api.zotero.org/users/{ZOTERO_USER_ID}/items\"\n",
    "    headers = {\"Zotero-API-Key\": ZOTERO_API_KEY}\n",
    "    params = {\"q\": pdf_name, \"itemType\": \"attachment\", \"format\": \"json\"}\n",
    "    res = requests.get(url, headers=headers, params=params)\n",
    "    if res.status_code == 200:\n",
    "        try:\n",
    "            for item in res.json():\n",
    "                if item[\"data\"].get(\"title\") == pdf_name:\n",
    "                    parent_key = item[\"data\"].get(\"parentItem\")\n",
    "                    return f\"zotero://select/items/0_{parent_key}\", parent_key\n",
    "        except Exception as e:\n",
    "            print(\"Zotero JSON error:\", e)\n",
    "    return None, None\n",
    "\n",
    "# --- Jupyterè¡¨ç¤ºç”¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä½œæˆ ---\n",
    "def show_network_jupyter(center_source, doc_embeddings, doc_titles):\n",
    "    center_vec = doc_embeddings[center_source]\n",
    "    similarities = {\n",
    "        doc: float(np.dot(center_vec, vec))\n",
    "        for doc, vec in doc_embeddings.items()\n",
    "        if doc != center_source\n",
    "    }\n",
    "\n",
    "    top_docs = sorted(similarities.items(), key=lambda x: x[1], reverse=True)[:TOP_K]\n",
    "\n",
    "    cyto = CytoscapeWidget()\n",
    "    cyto.set_style([\n",
    "        {\n",
    "            'selector': 'node',\n",
    "            'style': {\n",
    "                'label': 'data(label)',\n",
    "                'background-color': '#0074D9',\n",
    "                'width': '30',\n",
    "                'height': '30'\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'selector': '[group = \"center\"]',\n",
    "            'style': {\n",
    "                'background-color': 'red',\n",
    "                'width': '40',\n",
    "                'height': '40'\n",
    "            }\n",
    "        }\n",
    "    ])\n",
    "    cyto.set_layout(**COSE_LAYOUT_PARAMS)\n",
    "\n",
    "    center_title = doc_titles.get(center_source, center_source)\n",
    "    cyto.graph.add_node(Node(data={\"id\": center_source, \"label\": center_title[:50], \"group\": \"center\"}))\n",
    "\n",
    "    for doc, score in top_docs:\n",
    "        title = doc_titles.get(doc, doc)\n",
    "        cyto.graph.add_node(Node(data={\"id\": doc, \"label\": title[:50]}))\n",
    "        if score > EDGE_THRESHOLD:\n",
    "            cyto.graph.add_edge(Edge(data={\"source\": center_source, \"target\": doc}))\n",
    "\n",
    "    for i in range(len(top_docs)):\n",
    "        for j in range(i + 1, len(top_docs)):\n",
    "            doc1, doc2 = top_docs[i][0], top_docs[j][0]\n",
    "            sim_ij = float(np.dot(doc_embeddings[doc1], doc_embeddings[doc2]))\n",
    "            if sim_ij > EDGE_THRESHOLD:\n",
    "                cyto.graph.add_edge(Edge(data={\"source\": doc1, \"target\": doc2}))\n",
    "\n",
    "    def on_click_handler(node):\n",
    "        source_id = node['data']['id']\n",
    "        link, _ = get_zotero_link_and_key(source_id)\n",
    "        if link:\n",
    "            print(f\"Zoteroãƒªãƒ³ã‚¯ã‚’é–‹ãã¾ã™: {link}\")\n",
    "            webbrowser.open(link)\n",
    "        else:\n",
    "            print(\"Zoteroãƒªãƒ³ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\")\n",
    "\n",
    "    cyto.on(\"node\", \"click\", on_click_handler)\n",
    "\n",
    "    display(cyto)\n",
    "\n",
    "# --- å®Ÿè¡Œæº–å‚™ ---\n",
    "doc_embeddings, doc_titles = compute_doc_embeddings(paragraph_embeddings, metadata_list)\n",
    "title_to_source = {v: k for k, v in doc_titles.items()}\n",
    "all_titles = sorted(title_to_source.keys())\n",
    "\n",
    "search_box = widgets.Text(description=\"æ¤œç´¢:\", layout=widgets.Layout(width='400px'))\n",
    "dropdown = widgets.Dropdown(options=[], description=\"å€™è£œ:\", layout=widgets.Layout(width='95%'))\n",
    "run_button = widgets.Button(description=\"ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¡¨ç¤º\")\n",
    "\n",
    "# æ¤œç´¢ã§å€™è£œçµã‚Šè¾¼ã¿\n",
    "def on_search_change(change):\n",
    "    query = search_box.value.strip().lower()\n",
    "    filtered = [t for t in all_titles if query in t.lower()]\n",
    "    dropdown.options = filtered if filtered else [\"è©²å½“ãªã—\"]\n",
    "\n",
    "search_box.observe(on_search_change, names='value')\n",
    "\n",
    "# ãƒœã‚¿ãƒ³ã§è¡¨ç¤º\n",
    "def on_run_clicked(b):\n",
    "    selected_title = dropdown.value\n",
    "    if selected_title == \"è©²å½“ãªã—\":\n",
    "        print(\"âš ï¸ å€™è£œãŒã‚ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "        return\n",
    "    selected_source = title_to_source[selected_title]\n",
    "    show_network_jupyter(selected_source, doc_embeddings, doc_titles)\n",
    "\n",
    "run_button.on_click(on_run_clicked)\n",
    "\n",
    "# è¡¨ç¤º\n",
    "display(search_box, dropdown, run_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5773477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from ipycytoscape import CytoscapeWidget, Node, Edge\n",
    "from IPython.display import display\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import webbrowser\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# === ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®šï¼ˆã“ã“ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ï¼‰ ===\n",
    "TOP_K = 20                      # è¡¨ç¤ºã™ã‚‹ãƒãƒ¼ãƒ‰æ•°ï¼ˆä¸­å¿ƒè«–æ–‡ã«ä¼¼ã¦ã„ã‚‹ã‚‚ã®ï¼‰\n",
    "EDGE_THRESHOLD = 0.75          # ã‚¨ãƒƒã‚¸ã‚’ã¤ãªãé¡ä¼¼åº¦ã®é–¾å€¤\n",
    "\n",
    "# COSEãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆåˆæœŸè¨­å®šï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ï¼‰\n",
    "COSE_LAYOUT_PARAMS = {\n",
    "    \"name\": \"cose\",\n",
    "    \"animate\": False\n",
    "}\n",
    "\n",
    "# --- ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿ ---\n",
    "load_dotenv()\n",
    "ZOTERO_USER_ID = os.getenv(\"ZOTERO_USER_ID\")\n",
    "ZOTERO_API_KEY = os.getenv(\"ZOTERO_API_KEY\")\n",
    "PDF_FOLDER = os.getenv(\"PDF_FOLDER\", \"\")\n",
    "\n",
    "# --- ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ ---\n",
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "data = np.load(\"faiss_metadata.npz\", allow_pickle=True)\n",
    "metadata_list = data[\"metadata_list\"].tolist()\n",
    "paragraph_embeddings = data[\"embeddings\"]\n",
    "\n",
    "# --- æ–‡æ›¸å¹³å‡ãƒ™ã‚¯ãƒˆãƒ«ã®è¨ˆç®— ---\n",
    "def compute_doc_embeddings(paragraph_embeddings, metadata_list):\n",
    "    doc_vectors = defaultdict(list)\n",
    "    for emb, meta in zip(paragraph_embeddings, metadata_list):\n",
    "        doc_vectors[meta[\"source\"]].append(emb)\n",
    "\n",
    "    doc_embeddings = {}\n",
    "    doc_titles = {}\n",
    "    for source, vectors in doc_vectors.items():\n",
    "        vecs = np.vstack(vectors)\n",
    "        vecs /= np.linalg.norm(vecs, axis=1, keepdims=True)\n",
    "        mean_vec = np.mean(vecs, axis=0)\n",
    "        mean_vec /= np.linalg.norm(mean_vec)\n",
    "        doc_embeddings[source] = mean_vec.astype(\"float32\")\n",
    "        title = next((m[\"title\"] for m in metadata_list if m[\"source\"] == source), source)\n",
    "        doc_titles[source] = title\n",
    "    return doc_embeddings, doc_titles\n",
    "\n",
    "# --- Zoteroãƒªãƒ³ã‚¯ã¨parentKeyå–å¾— ---\n",
    "def get_zotero_link_and_key(source):\n",
    "    pdf_name = source.replace(PDF_FOLDER, \"\").lstrip(\"/\\\\\")\n",
    "    url = f\"https://api.zotero.org/users/{ZOTERO_USER_ID}/items\"\n",
    "    headers = {\"Zotero-API-Key\": ZOTERO_API_KEY}\n",
    "    params = {\"q\": pdf_name, \"itemType\": \"attachment\", \"format\": \"json\"}\n",
    "    res = requests.get(url, headers=headers, params=params)\n",
    "    if res.status_code == 200:\n",
    "        try:\n",
    "            for item in res.json():\n",
    "                if item[\"data\"].get(\"title\") == pdf_name:\n",
    "                    parent_key = item[\"data\"].get(\"parentItem\")\n",
    "                    return f\"zotero://select/items/0_{parent_key}\", parent_key\n",
    "        except Exception as e:\n",
    "            print(\"Zotero JSON error:\", e)\n",
    "    return None, None\n",
    "\n",
    "# --- Jupyterè¡¨ç¤ºç”¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä½œæˆ ---\n",
    "def show_network_jupyter(center_source, doc_embeddings, doc_titles):\n",
    "    center_vec = doc_embeddings[center_source]\n",
    "    similarities = {\n",
    "        doc: float(np.dot(center_vec, vec))\n",
    "        for doc, vec in doc_embeddings.items()\n",
    "        if doc != center_source\n",
    "    }\n",
    "\n",
    "    top_docs = sorted(similarities.items(), key=lambda x: x[1], reverse=True)[:TOP_K]\n",
    "\n",
    "    cyto = CytoscapeWidget()\n",
    "    cyto.set_style([\n",
    "        {\n",
    "            'selector': 'node',\n",
    "            'style': {\n",
    "                'label': 'data(label)',\n",
    "                'text-valign': 'center',\n",
    "                'text-halign': 'center',\n",
    "                'text-background-color': 'white',\n",
    "                'text-background-opacity': 1,\n",
    "                'text-background-shape': 'roundrectangle',\n",
    "                'text-border-color': '#999',\n",
    "                'text-border-width': 1,\n",
    "                'text-border-opacity': 0.5,\n",
    "                'background-color': '#0074D9',\n",
    "                'width': '30',\n",
    "                'height': '30',\n",
    "                'font-size': 10\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'selector': '[group = \"center\"]',\n",
    "            'style': {\n",
    "                'background-color': 'red',\n",
    "                'width': '40',\n",
    "                'height': '40'\n",
    "            }\n",
    "        }\n",
    "    ])\n",
    "    cyto.set_layout(**COSE_LAYOUT_PARAMS)\n",
    "\n",
    "    center_title = doc_titles.get(center_source, center_source)\n",
    "    cyto.graph.add_node(Node(data={\"id\": center_source, \"label\": center_title[:50], \"group\": \"center\"}))\n",
    "\n",
    "    for doc, score in top_docs:\n",
    "        title = doc_titles.get(doc, doc)\n",
    "        cyto.graph.add_node(Node(data={\"id\": doc, \"label\": title[:50]}))\n",
    "        if score > EDGE_THRESHOLD:\n",
    "            cyto.graph.add_edge(Edge(data={\"source\": center_source, \"target\": doc}))\n",
    "\n",
    "    for i in range(len(top_docs)):\n",
    "        for j in range(i + 1, len(top_docs)):\n",
    "            doc1, doc2 = top_docs[i][0], top_docs[j][0]\n",
    "            sim_ij = float(np.dot(doc_embeddings[doc1], doc_embeddings[doc2]))\n",
    "            if sim_ij > EDGE_THRESHOLD:\n",
    "                cyto.graph.add_edge(Edge(data={\"source\": doc1, \"target\": doc2}))\n",
    "\n",
    "    def on_click_handler(node):\n",
    "        source_id = node['data']['id']\n",
    "        link, _ = get_zotero_link_and_key(source_id)\n",
    "        if link:\n",
    "            print(f\"Zoteroãƒªãƒ³ã‚¯ã‚’é–‹ãã¾ã™: {link}\")\n",
    "            webbrowser.open(link)\n",
    "        else:\n",
    "            print(\"Zoteroãƒªãƒ³ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\")\n",
    "\n",
    "    cyto.on(\"node\", \"click\", on_click_handler)\n",
    "\n",
    "    display(cyto)\n",
    "\n",
    "# --- å®Ÿè¡Œæº–å‚™ ---\n",
    "doc_embeddings, doc_titles = compute_doc_embeddings(paragraph_embeddings, metadata_list)\n",
    "title_to_source = {v: k for k, v in doc_titles.items()}\n",
    "all_titles = sorted(title_to_source.keys())\n",
    "\n",
    "search_box = widgets.Text(description=\"æ¤œç´¢:\", layout=widgets.Layout(width='400px'))\n",
    "dropdown = widgets.Dropdown(options=[], description=\"å€™è£œ:\", layout=widgets.Layout(width='95%'))\n",
    "run_button = widgets.Button(description=\"ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¡¨ç¤º\")\n",
    "output_area = widgets.Output()\n",
    "\n",
    "# æ¤œç´¢ã§å€™è£œçµã‚Šè¾¼ã¿\n",
    "def on_search_change(change):\n",
    "    query = search_box.value.strip().lower()\n",
    "    filtered = [t for t in all_titles if query in t.lower()]\n",
    "    dropdown.options = filtered if filtered else [\"è©²å½“ãªã—\"]\n",
    "\n",
    "search_box.observe(on_search_change, names='value')\n",
    "\n",
    "# ãƒœã‚¿ãƒ³ã§è¡¨ç¤º\n",
    "def on_run_clicked(b):\n",
    "    selected_title = dropdown.value\n",
    "    with output_area:\n",
    "        output_area.clear_output()\n",
    "        if selected_title == \"è©²å½“ãªã—\":\n",
    "            print(\"âš ï¸ å€™è£œãŒã‚ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "            return\n",
    "        selected_source = title_to_source[selected_title]\n",
    "        show_network_jupyter(selected_source, doc_embeddings, doc_titles)\n",
    "\n",
    "run_button.on_click(on_run_clicked)\n",
    "\n",
    "# è¡¨ç¤º\n",
    "display(search_box, dropdown, run_button, output_area)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff79168a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open_manus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
