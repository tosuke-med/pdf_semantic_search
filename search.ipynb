{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#クエリに対する論文の検索・表示（gemini使用なし）\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# == パラメータ ==\n",
    "INDEX_FILE = \"faiss_index.bin\"\n",
    "METADATA_NPZ = \"faiss_metadata.npz\"\n",
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "EMB_DIM = 384\n",
    "TOP_K = 5  # 上位何件を表示するか\n",
    "\n",
    "# == モデル読込 ==\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "# == FAISSインデックス読込 ==\n",
    "index = faiss.read_index(INDEX_FILE)\n",
    "\n",
    "# == メタデータと段落を読み込む ==\n",
    "data = np.load(METADATA_NPZ, allow_pickle=True)\n",
    "metadata_list = data[\"metadata_list\"].tolist()  # np.array => Python list\n",
    "paragraphs = data[\"paragraphs\"].tolist()        # ✅ 段落テキストも読み込む\n",
    "\n",
    "print(\"インデックスとメタデータを読み込みました。ベクトル数:\", index.ntotal)\n",
    "\n",
    "# == 検索関数 ==\n",
    "def search_faiss(query, top_k=TOP_K):\n",
    "    # Sentence-BERTで埋め込み (float32)\n",
    "    emb_query = model.encode([query], show_progress_bar=False)\n",
    "    emb_query = emb_query.astype(\"float32\")\n",
    "\n",
    "    # コサイン類似度にするためクエリベクトルを正規化 (FAISS側は内積で検索)\n",
    "    # embedding / norm => 単位ベクトル\n",
    "    norm = np.sqrt((emb_query * emb_query).sum(axis=1, keepdims=True))\n",
    "    emb_query = emb_query / norm\n",
    "\n",
    "    # 類似度検索\n",
    "    # 距離 => 内積(IndexFlatIP)の場合、高いほど類似度が高い\n",
    "    D, I = index.search(emb_query, top_k)\n",
    "    # D.shape = (1, top_k), I.shape = (1, top_k)\n",
    "\n",
    "    results = []\n",
    "    for score, idx in zip(D[0], I[0]):\n",
    "        item = metadata_list[idx]\n",
    "        paragraph_text = \"\"  # JSONや別ファイルから取得してもよい\n",
    "        # もし段落テキストも保持しているなら embeddings の順番に対応させる必要がある\n",
    "        # ここでは \"paragraphs.jsonl\" から読み込んだ順に paragraphs[] に格納していた想定\n",
    "        # => idx番目の paragraphs[idx]\n",
    "        # ただし今は metadata_list に入れていないかもしれないので、やり方は要調整\n",
    "        # 例: item[\"paragraph\"] を最初にメタ情報として持っていれば良い\n",
    "        #     or paragraphs[] をグローバルに持っていればいい\n",
    "        # 今回の例では metadata_listにidがあるので、そちらを使いあとで再取得も可\n",
    "\n",
    "        # もし metadata_list と paragraphs が同じ順で保持されているなら:\n",
    "        paragraph_text = paragraphs[idx]  # search用に一時的にロードしておくか、Notebook内で持っておく\n",
    "\n",
    "        results.append({\n",
    "            \"score\": float(score),\n",
    "            \"text\": paragraph_text,\n",
    "            \"metadata\": item\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "# == GUIパーツ準備 ==\n",
    "query_box = widgets.Text(\n",
    "    description=\"Query:\",\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "search_button = widgets.Button(description=\"Search\")\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def on_search_clicked(b):\n",
    "    with output_area:\n",
    "        output_area.clear_output()\n",
    "        query = query_box.value.strip()\n",
    "        if not query:\n",
    "            display(HTML(\"<b>クエリを入力してください。</b>\"))\n",
    "            return\n",
    "\n",
    "        results = search_faiss(query, top_k=TOP_K)\n",
    "\n",
    "        html_content = \"\"\n",
    "        html_content += f\"<h3>検索クエリ: {query}</h3>\"\n",
    "        html_content += \"<ol>\"\n",
    "        for r in results:\n",
    "            score = r[\"score\"]\n",
    "            text = r[\"text\"]\n",
    "            meta = r[\"metadata\"]\n",
    "            # 表示をHTMLで整形\n",
    "            html_content += f\"<li><b>Score:</b> {score:.4f} <br>\"\n",
    "            html_content += f\"<b>ID:</b> {meta.get('id')}<br>\"\n",
    "            html_content += f\"<b>Page:</b> {meta.get('page')}<br>\"\n",
    "            html_content += f\"<b>Source:</b> {meta.get('source')}<br>\"\n",
    "            html_content += f\"<div style='margin-top:5px; border:1px solid #ccc; padding:5px;'>{text}</div></li><br>\"\n",
    "        html_content += \"</ol>\"\n",
    "\n",
    "        display(HTML(html_content))\n",
    "\n",
    "search_button.on_click(on_search_clicked)\n",
    "\n",
    "# == 画面表示 ==\n",
    "display(query_box, search_button, output_area)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#英語でクエリ入力・回答生成（gemini APIを使用）\n",
    "import numpy as np\n",
    "import faiss\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # .envファイルを読み込む\n",
    "\n",
    "API_KEY = os.getenv(\"GEMINI_API_KEY\") # 環境変数からAPIキーを取得\n",
    "\n",
    "# === 設定 ===  \n",
    "INDEX_FILE = 'faiss_index.bin'\n",
    "METADATA_NPZ = 'faiss_metadata.npz'\n",
    "MODEL_NAME = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "EMB_DIM = 384\n",
    "TOP_K = 5\n",
    "\n",
    "# === Gemini初期化 ===\n",
    "genai.configure(api_key=API_KEY)\n",
    "# === モデル・インデックス・データロード ===\n",
    "print(\"Loading model...\")\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "print(\"Loading FAISS index...\")\n",
    "index = faiss.read_index(INDEX_FILE)\n",
    "\n",
    "print(\"Loading metadata...\")\n",
    "data = np.load(METADATA_NPZ, allow_pickle=True)\n",
    "metadata_list = data['metadata_list'].tolist()\n",
    "paragraphs = data['paragraphs'].tolist()\n",
    "\n",
    "# === 検索関数 ===\n",
    "def search_faiss(query, k=TOP_K):\n",
    "    q_vec = model.encode([query], convert_to_numpy=True).astype('float32')\n",
    "    faiss.normalize_L2(q_vec)\n",
    "    D, I = index.search(q_vec, k)\n",
    "\n",
    "    results = []\n",
    "    for score, idx in zip(D[0], I[0]):\n",
    "        para_text = paragraphs[idx]\n",
    "        meta = metadata_list[idx]\n",
    "        results.append({\n",
    "            'score': float(score),\n",
    "            'paragraph': para_text,\n",
    "            'metadata': meta\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# === Geminiで回答生成（引用番号付き）===\n",
    "def generate_answer_with_gemini(query, top_results):\n",
    "    context_str_list = []\n",
    "    for i, r in enumerate(top_results, 1):\n",
    "        para_text = r['paragraph']\n",
    "        context_str_list.append(f\"[{i}] {para_text}\")\n",
    "\n",
    "    context_str = \"\\n\\n\".join(context_str_list)\n",
    "    prompt = (\n",
    "        f\"Use the numbered context paragraphs below to answer the question concisely. \"\n",
    "        f\"Reference the sources using [1], [2], etc., where appropriate.\\n\\n\"\n",
    "        f\"{context_str}\\n\\n\"\n",
    "        f\"Question: {query}\\n\\n\"\n",
    "        f\"Answer:\"\n",
    "    )\n",
    "\n",
    "    model_gemini = genai.GenerativeModel('models/gemini-1.5-flash-latest')\n",
    "    response = model_gemini.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "# === GUI部分 ===\n",
    "query_box = widgets.Text(\n",
    "    description='Query:',\n",
    "    layout=widgets.Layout(width='500px'),\n",
    "    placeholder='Enter your question...'\n",
    ")\n",
    "search_button = widgets.Button(description=\"Search & Answer\", button_style='success')\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def on_search_clicked(b):\n",
    "    with output_area:\n",
    "        output_area.clear_output()\n",
    "        query = query_box.value.strip()\n",
    "        if not query:\n",
    "            display(HTML(\"<b style='color:red;'>Please enter a query.</b>\"))\n",
    "            return\n",
    "        \n",
    "        print(\"Searching documents...\")\n",
    "        top_results = search_faiss(query, k=TOP_K)\n",
    "        \n",
    "        print(\"Generating answer with Gemini...\")\n",
    "        answer = generate_answer_with_gemini(query, top_results)\n",
    "\n",
    "        # 結果表示\n",
    "        display(HTML(f\"<h3>Gemini Answer</h3><p>{answer}</p>\"))\n",
    "\n",
    "        # 引用文献表示\n",
    "        html_refs = \"<h4>References</h4><ol>\"\n",
    "        for i, r in enumerate(top_results, 1):\n",
    "            meta = r['metadata']\n",
    "            html_refs += (\n",
    "                f\"<li><b>{meta.get('title')}</b> (page {meta.get('page')})<br>\"\n",
    "                f\"<i>{meta.get('source')}</i></li>\"\n",
    "            )\n",
    "        html_refs += \"</ol>\"\n",
    "        display(HTML(html_refs))\n",
    "\n",
    "search_button.on_click(on_search_clicked)\n",
    "\n",
    "# === 表示 ===\n",
    "display(widgets.VBox([query_box, search_button, output_area]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#日本語対応（クエリの翻訳にもgeminiを使用）\n",
    "import numpy as np\n",
    "import faiss\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# === 環境変数の読み込み ===\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "# === Gemini初期化 ===\n",
    "genai.configure(api_key=API_KEY)\n",
    "\n",
    "# === 設定 ===\n",
    "INDEX_FILE = 'faiss_index.bin'\n",
    "METADATA_NPZ = 'faiss_metadata.npz'\n",
    "MODEL_NAME = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "EMB_DIM = 384\n",
    "TOP_K = 5\n",
    "\n",
    "# === モデル・インデックス・メタデータの読み込み ===\n",
    "print(\"Loading model...\")\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "print(\"Loading FAISS index...\")\n",
    "index = faiss.read_index(INDEX_FILE)\n",
    "\n",
    "print(\"Loading metadata...\")\n",
    "data = np.load(METADATA_NPZ, allow_pickle=True)\n",
    "metadata_list = data['metadata_list'].tolist()\n",
    "paragraphs = data['paragraphs'].tolist()\n",
    "\n",
    "# === Geminiで日本語→英語 翻訳 ===\n",
    "def translate_query_to_english(japanese_query):\n",
    "    prompt = f\"次の日本語を正確な英語に翻訳してください：\\n\\n{japanese_query}\"\n",
    "    translator = genai.GenerativeModel('models/gemini-1.5-flash-latest')\n",
    "    response = translator.generate_content(prompt)\n",
    "    return response.text.strip()\n",
    "\n",
    "# === FAISS検索関数 ===\n",
    "def search_faiss(query, k=TOP_K):\n",
    "    q_vec = model.encode([query], convert_to_numpy=True).astype('float32')\n",
    "    faiss.normalize_L2(q_vec)\n",
    "    D, I = index.search(q_vec, k)\n",
    "\n",
    "    results = []\n",
    "    for score, idx in zip(D[0], I[0]):\n",
    "        para_text = paragraphs[idx]\n",
    "        meta = metadata_list[idx]\n",
    "        results.append({\n",
    "            'score': float(score),\n",
    "            'paragraph': para_text,\n",
    "            'metadata': meta\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# === Geminiで回答生成（日本語出力・出典番号付き）===\n",
    "def generate_answer_with_gemini(original_japanese_query, top_results):\n",
    "    context_str_list = []\n",
    "    for i, r in enumerate(top_results, 1):\n",
    "        para_text = r['paragraph']\n",
    "        context_str_list.append(f\"[{i}] {para_text}\")\n",
    "\n",
    "    context_str = \"\\n\\n\".join(context_str_list)\n",
    "    prompt = (\n",
    "        f\"以下の番号付きの文脈を参考にして、質問に日本語で簡潔に答えてください。\\n\"\n",
    "        f\"適切な箇所には [1], [2] などで出典を示してください。\\n\\n\"\n",
    "        f\"{context_str}\\n\\n\"\n",
    "        f\"質問: {original_japanese_query}\\n\\n\"\n",
    "        f\"回答:\"\n",
    "    )\n",
    "\n",
    "    model_gemini = genai.GenerativeModel('models/gemini-1.5-flash-latest')\n",
    "    response = model_gemini.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "# === GUI作成 ===\n",
    "query_box = widgets.Text(\n",
    "    description='質問:',\n",
    "    layout=widgets.Layout(width='500px'),\n",
    "    placeholder='日本語で質問を入力してください...'\n",
    ")\n",
    "search_button = widgets.Button(description=\"検索 & 回答生成\", button_style='success')\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def on_search_clicked(b):\n",
    "    with output_area:\n",
    "        output_area.clear_output()\n",
    "        japanese_query = query_box.value.strip()\n",
    "        if not japanese_query:\n",
    "            display(HTML(\"<b style='color:red;'>質問を入力してください。</b>\"))\n",
    "            return\n",
    "\n",
    "        print(\"英語に翻訳中...\")\n",
    "        english_query = translate_query_to_english(japanese_query)\n",
    "\n",
    "        print(\"FAISSで検索中...\")\n",
    "        top_results = search_faiss(english_query, k=TOP_K)\n",
    "\n",
    "        print(\"Geminiで回答生成中...\")\n",
    "        answer = generate_answer_with_gemini(japanese_query, top_results)\n",
    "\n",
    "        # 回答表示\n",
    "        display(HTML(f\"<h3>Geminiの回答</h3><p>{answer}</p>\"))\n",
    "\n",
    "        # 引用文献表示\n",
    "        html_refs = \"<h4>出典</h4><ol>\"\n",
    "        for i, r in enumerate(top_results, 1):\n",
    "            meta = r['metadata']\n",
    "            html_refs += (\n",
    "                f\"<li><b>{meta.get('title')}</b> (page {meta.get('page')})<br>\"\n",
    "                f\"<i>{meta.get('source')}</i></li>\"\n",
    "            )\n",
    "        html_refs += \"</ol>\"\n",
    "        display(HTML(html_refs))\n",
    "\n",
    "search_button.on_click(on_search_clicked)\n",
    "\n",
    "# === 表示 ===\n",
    "display(widgets.VBox([query_box, search_button, output_area]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open_manus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
