{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PDFからテキスト抽出、2段組み対応、近い座標のブロックを２００単語以上でまとめる設定\n",
    "import fitz\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "PDF_FOLDER = os.getenv(\"PDF_FOLDER\")\n",
    "OUTPUT_JSONL = \"paragraphs.jsonl\"\n",
    "\n",
    "# すでに処理済みのIDをロード\n",
    "if os.path.exists(OUTPUT_JSONL):\n",
    "    with open(OUTPUT_JSONL, \"r\", encoding=\"utf-8\") as f:\n",
    "        processed_ids = {json.loads(line)[\"id\"] for line in f}\n",
    "else:\n",
    "    processed_ids = set()\n",
    "\n",
    "pdf_files = []\n",
    "for root, _, files in os.walk(PDF_FOLDER):\n",
    "    for file in files:\n",
    "        if file.lower().endswith(\".pdf\"):\n",
    "            pdf_files.append(os.path.join(root, file))\n",
    "\n",
    "print(f\"PDFファイル数: {len(pdf_files)}\")\n",
    "\n",
    "def combine_close_blocks(blocks, x_margin=50, y_margin=10):\n",
    "    \"\"\"\n",
    "    (x0, y0, x1, y1, text) のリストを受け取り、\n",
    "    上→下、左→右ソート後「近い位置(x,y)」のブロックを一つの段落にまとめる。\n",
    "    \"\"\"\n",
    "    blocks_sorted = sorted(blocks, key=lambda b: (b[1], b[0]))  # y0, x0 でソート\n",
    "\n",
    "    paragraphs = []\n",
    "    current_text = \"\"\n",
    "    prev_block = None\n",
    "\n",
    "    for block in blocks_sorted:\n",
    "        x0, y0, x1, y1, text = block\n",
    "\n",
    "        if prev_block is not None:\n",
    "            px0, py0, px1, py1, ptext = prev_block\n",
    "            same_column = (abs(x0 - px0) < x_margin)   # 横方向のずれが小さい\n",
    "            vertical_gap = abs(y0 - py1)               # 縦方向の隙間が小さい\n",
    "\n",
    "            if same_column and (vertical_gap < y_margin):\n",
    "                # 同じ段落とみなして結合\n",
    "                if current_text:\n",
    "                    current_text += \" \"\n",
    "                current_text += text\n",
    "            else:\n",
    "                paragraphs.append(current_text.strip())\n",
    "                current_text = text\n",
    "        else:\n",
    "            current_text = text\n",
    "\n",
    "        prev_block = block\n",
    "\n",
    "    # 最後の段落が残っていれば追加\n",
    "    if current_text:\n",
    "        paragraphs.append(current_text.strip())\n",
    "\n",
    "    return paragraphs\n",
    "\n",
    "def merge_short_paragraphs_both_ends(paragraphs, min_words=100):\n",
    "    \"\"\"\n",
    "    「短い段落は次の段落と結合」を繰り返す + \n",
    "    それでも最後に短い段落が残れば前の段落にくっつける\n",
    "\n",
    "    - min_words: これ未満の段落は短いとみなして結合\n",
    "    \"\"\"\n",
    "\n",
    "    if not paragraphs:\n",
    "        return []\n",
    "\n",
    "    merged = []\n",
    "    i = 0\n",
    "    n = len(paragraphs)\n",
    "\n",
    "    # 1) 前方からスキャンして、短い段落は次に合体\n",
    "    while i < n:\n",
    "        current_para = paragraphs[i]\n",
    "        current_words = len(current_para.split())\n",
    "\n",
    "        if current_words >= min_words:\n",
    "            # 充分長いなら確定\n",
    "            merged.append(current_para)\n",
    "            i += 1\n",
    "        else:\n",
    "            # 次の段落を巻き込む\n",
    "            j = i + 1\n",
    "            combined = current_para\n",
    "            combined_words = current_words\n",
    "\n",
    "            while j < n and combined_words < min_words:\n",
    "                combined += \" \" + paragraphs[j]\n",
    "                combined_words = len(combined.split())\n",
    "                j += 1\n",
    "\n",
    "            merged.append(combined.strip())\n",
    "            i = j\n",
    "\n",
    "    # 2) もし最後の段落がまだ短いなら、前の段落と合体\n",
    "    if len(merged) >= 2:\n",
    "        last_para = merged[-1]\n",
    "        if len(last_para.split()) < min_words:\n",
    "            # 前の段落がある限り合体\n",
    "            merged[-2] = merged[-2] + \" \" + last_para\n",
    "            merged.pop()  # 最後の段落を削除\n",
    "\n",
    "    return merged\n",
    "\n",
    "def extract_paragraphs_1column(raw_blocks, x_margin=50, y_margin=10, min_words=100):\n",
    "    \"\"\"\n",
    "    シングルカラムとして全ブロックをまとめて処理。\n",
    "    \"\"\"\n",
    "    # (x0, y0, x1, y1, text)を取り出す\n",
    "    blocks = []\n",
    "    for b in raw_blocks:\n",
    "        x0, y0, x1, y1, txt = b[:5]\n",
    "        txt = txt.replace(\"-\\n\", \"\").replace(\"\\n\", \" \").strip()\n",
    "        if txt:\n",
    "            blocks.append((x0, y0, x1, y1, txt))\n",
    "\n",
    "    if not blocks:\n",
    "        return []\n",
    "\n",
    "    # まず近いブロックを結合\n",
    "    paras = combine_close_blocks(blocks, x_margin, y_margin)\n",
    "    # さらに短い段落を次々に結合し、最後に余ったら前に合体\n",
    "    paras_merged = merge_short_paragraphs_both_ends(paras, min_words=min_words)\n",
    "    return paras_merged\n",
    "\n",
    "def extract_paragraphs_2column(raw_blocks, page_width, x_margin=50, y_margin=10, min_words=100):\n",
    "    \"\"\"\n",
    "    2段組を想定し、左カラム/右カラムに分けて処理し、最後に結合。\n",
    "    \"\"\"\n",
    "    blocks_left = []\n",
    "    blocks_right = []\n",
    "\n",
    "    half_width = page_width / 2\n",
    "    for b in raw_blocks:\n",
    "        x0, y0, x1, y1, txt = b[:5]\n",
    "        txt = txt.replace(\"-\\n\", \"\").replace(\"\\n\", \" \").strip()\n",
    "        if not txt:\n",
    "            continue\n",
    "        if x0 < half_width:\n",
    "            blocks_left.append((x0, y0, x1, y1, txt))\n",
    "        else:\n",
    "            blocks_right.append((x0, y0, x1, y1, txt))\n",
    "\n",
    "    # 左カラム\n",
    "    left_paras = combine_close_blocks(blocks_left, x_margin, y_margin)\n",
    "    left_paras_merged = merge_short_paragraphs_both_ends(left_paras, min_words=min_words)\n",
    "\n",
    "    # 右カラム\n",
    "    right_paras = combine_close_blocks(blocks_right, x_margin, y_margin)\n",
    "    right_paras_merged = merge_short_paragraphs_both_ends(right_paras, min_words=min_words)\n",
    "\n",
    "    # 左→右の順で合体\n",
    "    return left_paras_merged + right_paras_merged\n",
    "\n",
    "def is_two_column(page, threshold=0.3):\n",
    "    \"\"\"\n",
    "    2段組とみなすかどうかを簡易判定。 \n",
    "    - threshold=0.3: 全ブロックのうち 30%以上が右側なら2段組とみなす\n",
    "    \"\"\"\n",
    "    raw_blocks = page.get_text(\"blocks\")\n",
    "    if not raw_blocks:\n",
    "        return False\n",
    "\n",
    "    page_width = page.rect.width\n",
    "    half_width = page_width / 2\n",
    "\n",
    "    total = 0\n",
    "    right_side = 0\n",
    "    for b in raw_blocks:\n",
    "        x0, y0, x1, y1, txt = b[:5]\n",
    "        if not txt.strip():\n",
    "            continue\n",
    "        total += 1\n",
    "        if x0 > half_width:\n",
    "            right_side += 1\n",
    "\n",
    "    if total == 0:\n",
    "        return False\n",
    "\n",
    "    ratio = right_side / total\n",
    "    return (ratio >= threshold)\n",
    "\n",
    "def extract_paragraphs(page, x_margin=50, y_margin=10, min_words=100):\n",
    "    \"\"\"\n",
    "    ページが2段組かどうかを判定して、適切な処理を呼び出す。\n",
    "    \"\"\"\n",
    "    raw_blocks = page.get_text(\"blocks\")\n",
    "    if not raw_blocks:\n",
    "        return []\n",
    "\n",
    "    if is_two_column(page, threshold=0.3):\n",
    "        # 2カラム処理\n",
    "        return extract_paragraphs_2column(raw_blocks, page.rect.width,\n",
    "                                          x_margin, y_margin, min_words)\n",
    "    else:\n",
    "        # シングルカラム処理\n",
    "        return extract_paragraphs_1column(raw_blocks,\n",
    "                                          x_margin, y_margin, min_words)\n",
    "\n",
    "\n",
    "with open(OUTPUT_JSONL, \"a\", encoding=\"utf-8\") as out_jsonl:\n",
    "    for pdf_file in pdf_files:\n",
    "        pdf_id = os.path.splitext(os.path.basename(pdf_file))[0]\n",
    "        print(f\"処理中: {os.path.basename(pdf_file)}\")\n",
    "\n",
    "        doc = fitz.open(pdf_file)\n",
    "        paragraphs_all_pages = []\n",
    "\n",
    "        for page_idx, page in enumerate(doc):\n",
    "            page_paragraphs = extract_paragraphs(\n",
    "                page,\n",
    "                x_margin=50,     # 段落結合の横方向閾値\n",
    "                y_margin=10,     # 段落結合の縦方向閾値\n",
    "                min_words=200    # 200単語未満の段落は次の段落(or最後に前の段落)と連結\n",
    "            )\n",
    "\n",
    "            for p in page_paragraphs:\n",
    "                paragraphs_all_pages.append((p, page_idx + 1))\n",
    "\n",
    "        doc.close()\n",
    "\n",
    "        # JSON Lines形式で書き出し\n",
    "        for i, (para_text, page_num) in enumerate(paragraphs_all_pages):\n",
    "            para_id = f\"{pdf_id}_p{i+1}\"\n",
    "            if para_id in processed_ids:\n",
    "                continue\n",
    "\n",
    "            entry = {\n",
    "                \"id\": para_id,\n",
    "                \"title\": pdf_id,\n",
    "                \"paragraph\": para_text,\n",
    "                \"metadata\": {\n",
    "                    \"page\": page_num,\n",
    "                    \"source\": pdf_file\n",
    "                }\n",
    "            }\n",
    "            out_jsonl.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"段落抽出完了。\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#チェック用\n",
    "import json\n",
    "\n",
    "INPUT_JSONL = \"paragraphs.jsonl\"\n",
    "OUTPUT_TXT = \"first_paper_paragraphs_preview.txt\"\n",
    "\n",
    "# 最初に登場した論文IDを記録\n",
    "first_paper_id = None\n",
    "\n",
    "with open(INPUT_JSONL, \"r\", encoding=\"utf-8\") as fin, open(OUTPUT_TXT, \"w\", encoding=\"utf-8\") as fout:\n",
    "    for line in fin:\n",
    "        data = json.loads(line)\n",
    "        title = data[\"title\"]\n",
    "\n",
    "        if first_paper_id is None:\n",
    "            first_paper_id = title  # 最初の論文IDを記録\n",
    "            print(f\"最初の論文: {first_paper_id}\")\n",
    "\n",
    "        if data[\"title\"] != first_paper_id:\n",
    "            continue  # 最初の論文以外はスキップ\n",
    "\n",
    "        para_id = data[\"id\"]\n",
    "        text = data[\"paragraph\"]\n",
    "        page = data[\"metadata\"][\"page\"]\n",
    "\n",
    "        fout.write(f\"--- {para_id} (page {page}) ---\\n\")\n",
    "        fout.write(text.strip() + \"\\n\\n\")\n",
    "\n",
    "print(f\"{first_paper_id} の段落を {OUTPUT_TXT} に出力しました。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open_manus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
